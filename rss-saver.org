* rss-saver
A script that saves my blog posts from [[https://world.hey.com/adam.james/]]

** readme
#+begin_src markdown :tangle ./readme.md
# RSS-saver
A simple Clojure (Babashka) script to save world@hey.com blog posts locally.

I use hey.com's blog feature to write blog posts to help me clarify and improve my own thinking about life, design, and programming. It's a cool feature to a nice service, but I worry that I may not be able to retrieve my posts in the event of service shutdown, or if I move on to another email provider in the future.

This script is meant to be run automatically every night (or so). It downloads the feed.atom xml file from the provided URL, checks for any changes from the previous download, and saves new entries.

## Status
Working 'skeleton'. I wrote this during one of my streams, and it works with my (hardcoded) blog RSS URL. I have to clean up the node transformation and open up the feature set slightly:

 - option to change the feed URL to other hey URLs. I am NOT worrying about other RSS feed formats at this time. Not sure if they are standardised anyway.
 - add a few output options: .txt, .md, .org, .html ?? Not entirely sure which yet.
 - make a proper CLI w/ help printout
 - make sure a GraalVM native-image build is possible

#+end_src

* What is RSS?
I've never properly learned what RSS actually is. Here's my RSS link that I'll be using:

[[https://world.hey.com/adam.james/feed.atom]]

I assume that the atom file at that address is automatically updated any time a post is created, and I assume it's just XML with all of the blog's content.

What I think RSS does:

Every time the site updates, the feed.atom file is re-generated with the newest content appended. Then, the RSS reader is a separate app that polls feed.atom URLs, downloads them, and parses/displays the contents according to the app's design.

* Design
This is a simple script that only saves my world.hey.com blog posts to text files. Run the script once, it will grab feed.atom from the URL, parse it, and save each post and its content as plaintext.

To expand that minimal scope, I want:

- basic diffing approach which saves the previous feed.atom file so that when the script runs, it can compare the newest feed from the previous, and only saves new articles.
- some articles have images, I would like to be able to download those images and save them inside a folder generated per post.
- I want to emit the posts in either markdown OR org files, not sure yet.

* main
** ns
Need xml parsing. Might need to build a zipper to edit nodes.

I'll want to run it as a CLI, and probably want to turn the project into another GRAALVM native image example, so I'll need tools.cli as well.

As part of the design criteria, I want this to work without pulling any new libraries from outside of the babashka tool. This means sticking with clojure.data.xml even though other libraries might be a little more straight forward. I can build a zipper editor easily enough so it's not a problem.

#+begin_src clojure :tangle ./rss-saver.clj
(ns rss-saver.main
  (:require [clojure.string :as str]
            [clojure.data.xml :as xml]
            [clojure.java.io :as io]
            [clojure.zip :as zip]
            [clojure.java.shell :as sh :refer [sh]]
            [clojure.tools.cli :as cli]
            [hiccup.core :refer [html]]))

#+end_src

** zipper tools
#+begin_src clojure :tangle ./rss-saver.clj
;; https://ravi.pckl.me/short/functional-xml-editing-using-zippers-in-clojure/
(defn edit-nodes
  [zipper matcher editor]
  (loop [loc zipper]
    (if (zip/end? loc)
      (zip/root loc)
      (if-let [matcher-result (matcher loc)]
        (let [new-loc (zip/edit loc editor)]
          (if (not (= (zip/node new-loc) (zip/node loc)))
            (recur (zip/next new-loc))
            (recur (zip/next loc))))
        (recur (zip/next loc))))))

(defn remove-nodes
  [zipper matcher]
  (loop [loc zipper]
    (if (zip/end? loc)
      (zip/root loc)
      (if-let [matcher-result (matcher loc)]
        (let [new-loc (zip/remove loc)]
          (recur (zip/next new-loc)))
        (recur (zip/next loc))))))

(defn get-nodes
  [zipper matcher]
  (loop [loc zipper
         acc []]
    (if (zip/end? loc)
      acc
      (if (matcher loc)
        (recur (zip/next loc) (conj acc (zip/node loc)))
        (recur (zip/next loc) acc)))))

(defn match-entry?
  [loc]
  (let [node (zip/node loc)
        {:keys [tag]} node]
    (= tag :entry)))
  
#+end_src

** entry nodes
#+begin_src clojure :tangle ./rss-saver.clj
(defn feed-str->entries
  "Returns a sequence of parsed article entry nodes from an XML feed string."
  [s]
  (-> s
      (xml/parse-str {:namespace-aware false})
      zip/xml-zip
      (get-nodes match-entry?)))

#+end_src

** node-transforms
*** normalize
#+begin_src clojure :tangle ./rss-saver.clj
(defn normalize-entry
  "Normalizes the entry node by flattening content into a map."
  [entry]
  (let [content (filter map? (:content entry))
        f (fn [{:keys [tag content] :as node}]
            (let [val (cond (= tag :link) (get-in node [:attrs :href])
                            :else (first content))]
                {tag val}))
        author-map (->> content
                        (filter #(= (:tag %) :author))
                        first :content
                        (filter map?)
                        (map f)
                        (apply merge))]
   (apply merge (conj
                 (map f (remove #(= (:tag %) :author) content))
                 author-map))))
#+end_src

*** clean-html
#+begin_src clojure :tangle ./rss-saver.clj
(defn match-tag
  [k]
  (fn
    [loc]
    (let [node (zip/node loc)
          {:keys [tag]} node]
      (= tag k))))

(defn wrap-strs-in-p-tags
  [node]
  (let [f (fn [item]
            (if (string? item)
              {:tag :p :attrs {} :content [item]}
              item))
        new-content (->> node
                         :content
                         (map f))]
    (assoc node :content new-content)))

(defn convert-to-p-tag
  [node]
  (assoc node :tag :p))

(defn unwrap-img-from-figure
  [node]
  (let [img-node (-> node
                 zip/xml-zip
                 (get-nodes (match-tag :img))
                 first)
        new-attrs (-> img-node
                      :attrs
                      (dissoc :srcset :decoding :loading))]
    (assoc img-node :attrs new-attrs)))

(defn clean-html
  "Clean up the html string from the feed."
  [s]
  (let [s (-> s
              (str/replace "<br>" "<br></br>")
              (str/replace #"<img[\w\W]+?>" #(str %1 "</img>")))]
    (-> s
        (xml/parse-str {:namespace-aware false})
        zip/xml-zip
        (edit-nodes (match-tag :figure) unwrap-img-from-figure)
        xml/emit-str
        (str/replace #"<\?xml[\w\W]+?>" ""))))

#+end_src

** hiccup
#+begin_src clojure :tangle ./rss-saver.clj
(defmulti node->hiccup
  (fn [node]
    (cond
      (map? node) (:tag node)
      (and (seqable? node) (not (string? node))) :list
      :else :string)))

(defmethod node->hiccup :string
  [node]
  (when-not (= (str/trim node) "") node))

(defn inline-elem? [item] (when (#{:em :strong} (first item)) true))
(defn inline? [item] (or (string? item) (inline-elem? item)))

(defn group-inline
  [list]
  (let [groups (partition-by inline? list)
        f (fn [list]
            (let [f (fn [[a b c]]
                      (cond
                        (and (string? a)
                             (inline-elem? b)
                             (string? c))
                        [:p a b c]
                        
                        :else
                        a))]
              (map f (partition-all 3 1 list))))]
    (->> groups
         (map f))))

(defn de-dupe
  [list]
  (->> list
       (partition-by identity)
       (map first)))

(defn selective-flatten
  ([l] (selective-flatten [] l))
  ([acc l]
   (if (seq l)
     (let [item (first l)
           xacc (if (or (string? item)
                        (and (vector? item) (keyword? (first item))))
                 (conj acc item)
                 (into [] (concat acc (selective-flatten item))))]
       (recur xacc (rest l)))
     (apply list acc))))

(defmethod node->hiccup :list
  [node]
  (->> node
       (map node->hiccup)
       (remove nil?)
       de-dupe
       selective-flatten))

(defmethod node->hiccup :div [node] (node->hiccup (:content node)))

#_(defmethod node->hiccup :img
  [{:keys [tag attrs]}]
  [tag attrs])

(defmethod node->hiccup :default
  [{:keys [tag attrs content]}]
  [tag attrs (node->hiccup content)])

#_(defmethod node->hiccup :br [node] [:br])

(defn html-str->hiccup
  "Parses and converts an html string to markdown."
  [s]
  (-> s
      (xml/parse-str {:namespace-aware false})
      node->hiccup))

(defn entry->hiccup
  "Converts a parsed XML entry node into a Hiccup data structure."
  [entry]
  (let [entry (normalize-entry entry)]
    {:id (:id entry)
     :post (->> entry :content
                clean-html
                html-str->hiccup
                #_selective-flatten)}))
#+end_src

** basic-html
#+begin_src clojure :tangle ./rss-saver.clj
(defn readable-date
  [s]
  (as-> s s
    (str/split s #"[a-zA-Z]")
    (str/join " " s)))

(defn entry->html
  "Converts a parsed XML entry node into an html document."
  [entry]
  (let [entry (normalize-entry entry)
        info-span (fn [label s]
                    [:span {:style {:display "block"
                                    :margin-bottom "2px"}}
                     [:strong label] s])]
    (assoc entry :post
           (str
            "<!DOCTYPE html>\n"
            (html
             (list
              [:head
               [:meta {:charset "utf-8"}]
               [:title (:title entry)]]
              [:body
               [:div {:class "post-info"}
                (info-span "Author: " (:name entry))
                (info-span "Email: " (:email entry))
                (info-span "Published: " (:published entry))
                (info-span "Updated: " (:updated entry))]
               [:a {:href (:link entry)} [:h1 (:title entry)]]
               (->> entry :content
                    clean-html
                    html-str->hiccup
                    html)]))))))
#+end_src

** CLI
#+begin_src clojure :tangle ./rss-saver.clj
(def cli-options
  [["-h" "--help"]
   ["-u" "--url URL" "The URL of the RSS feed you want to save."]
   ["-d" "--dir DIR" "The directory where articles will be saved."
    :default "./posts"]
   ["-f" "--format FORMAT" "The format of saved articles. Either 'html' or 'md' for markdown, defaulting to html if unspecified."
    :default "html"]
   ["-c" "--clear" "Clear the cached copy of the previous feed."]])

(defn clear!
  [opts]
  (let [prev-fname (str (:dir opts) "/" "previous-feed.atom")]
    (sh "rm" "-f" prev-fname)))

(defn save!
  [opts]
  (let [save-fn (get {"html" entry->html
                      "edn" entry->hiccup} (:format opts))
        cur-str (slurp (:url opts))
        prev-fname (str (:dir opts) "/" "previous-feed.atom")
        prev-str (when (.exists (io/file prev-fname))
                   (slurp prev-fname))
        prev (when prev-str (feed-str->entries prev-str))
        cur (feed-str->entries cur-str)
        entries (remove (into #{} prev) cur)]
    (if (> (count entries) 0)
      (do
        (println (str "Handling " (count entries) " entries."))
        (sh "mkdir" "-p" (:dir opts))
        (doseq [{:keys [id post]} (mapv save-fn entries)]
          (let [fname (str
                       (:dir opts) "/"
                       (second (str/split id #"/")) "."
                       (:format opts))]
            (spit fname post)))
        (spit prev-fname cur-str))
      (println "No changes found in feed."))))

(defn -main
  [& args]
  (let [parsed (cli/parse-opts args cli-options)
        opts (:options parsed)]
    (cond
      (:help opts)
      (println (str "Usage:" "\n" (:summary parsed)))

      (nil? (:url opts))
      (println "Please specify feed URL.")

      :else
      (do
        (when (:clear opts) (clear! opts))
        (save! opts)))))

(apply -main *command-line-args*)
(shutdown-agents)
#+end_src

* testing-defs
#+begin_src clojure
(def opts {:url "https://world.hey.com/adam.james/feed.atom"
           :dir "posts"
           :format "md"})

(def entries (feed-str->entries (slurp (:url opts))))
#_(entry->markdown (nth entries 6))
#_(save! opts)

#+end_src
