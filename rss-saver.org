* rss-saver
A simple Clojure (Babashka) script to save world@hey.com blog posts locally.

I use hey.com's blog feature to write blog posts to help me clarify and improve my own thinking about life, design, and programming. It's a cool feature of a nice email service, but I worry that I may not be able to retrieve my posts in the event of service shutdown, or if I move on to another email provider in the future.

This script is meant to be run automatically every night (or so) via a crontab entry. It downloads the feed.atom xml file from the provided URL, checks for any changes from the previous download, and saves new entries.

** readme
#+begin_src markdown :tangle ./readme.md
```
 ______________
|[]            |
|  __________  |
|  |  RSS-  |  |
|  | saver  |  |
|  |________|  |
|   ________   |
|   [ [ ]  ]   |
\___[_[_]__]___|

```

# RSS-saver
A simple Clojure (Babashka) script to save world@hey.com blog posts locally.

I use hey.com's blog feature to write blog posts to help me clarify and improve my own thinking about life, design, and programming. It's a cool feature of a nice email service, but I worry that I may not be able to retrieve my posts in the event of service shutdown, or if I move on to another email provider in the future.

This script is meant to be run automatically every night (or so) via a crontab entry. It downloads the feed.atom xml file from the provided URL, checks for any changes from the previous download, and saves new entries.

You can read the [design doc](./rss-saver.org#design) for a complete understanding of this project.

## Installation
If you already have the latest Babashka, all you have to do is grab the script from this repo:

```sh
git clone https://github.com/adam-james-v/rss-saver.git
cd rss-saver
```

And install the script `rss-saver.clj` wherever you like to run scripts from.

```sh
cp rss-saver.clj /path/to/your/scripts/dir
```

## Usage
To run this script once, you must supply the feed url with `-u` or `--url`. The provided URL must point to the rss feed XML file directly. For example, my URL is [https://world.hey.com/adam.james/feed.atom](https://world.hey.com/adam.james/feed.atom).

,**NOTE:** Your URL *must* point to the feed.xml file for this script to work.

```sh
bb rss-saver.clj -u YOUR_URL
```

The above command will download the XML file, parse and save to .edn files each post into the ./posts folder. You can change some options with the following:

```sh
Usage:
 -h, --help
 -u, --url URL                 The URL of the RSS feed you want to save.
 -d, --dir DIR        ./posts  The directory where articles will be saved.
 -f, --format FORMAT  edn      The format of saved articles. Either 'html' or
                               'edn' for a Clojure Map with the post saved as
                               Hiccup style syntax. Defaults to edn if unspecified.
 -c, --clear                   Clear the cached copy of the previous feed.
 -s, --silent                  Silence the script's output.
```

I use this script with an automation using crontab on macOS. My crontab entry:

```sh
0 12 * * * /usr/local/bin/bb /Users/adam/scripts/rss-saver.clj -u https://world.hey.com/adam.james/feed.atom
```

Which runs the script once at noon every day. It's default save directory is ./posts, so my articles are saved in `/Users/adam/scripts/rss-saver/posts`, but you can set the path to wherever you want using the `-d` or `--dir` options. I recommend using an absolute path to avoid confusion.

## Requirements
RSS-Saver requires [Babashka](https://github.com/babashka/babashka). While writing this script, I was using *version 0.6.0*. The script uses the following libraries, which are bundled with the latest Babashka:

 - clojure.string
 - clojure.data.xml
 - clojure.java.io
 - clojure.zip
 - clojure.java.shell
 - clojure.tools.cli
 - hiccup.core

If you want to run things automatically, you need some mechanism to automate running scripts. I am using crontab.

## Status
The script is complete and working as intended. Bugs will be fixed if I encounter them or if someone posts an issue. This is intended to be a *very* simple script with a small and specific scope, so new features won't be implemented. This project is *done* (Yay!).

#+end_src

* Design
The problem that RSS-saver solves is one of backing up and keeping open access to my blog posts on [[https://world.hey.com/adam.james]]; a useful blog service offered to paying Hey email users. I enjoy this service and intend to keep using it for some time, but there's always the potential that the service changes or disappears, or I change my mind about using it. In such a case, I want to be certain that my blog posts are still available to me in some useful form.

So, this project has the following requirements:

 - automatically download the RSS feed XML
 - parse the feed into individual entries
 - cache the feed to avoid constantly re-parsing downloaded posts
 - save entries in an open format
 - runnable as a Babashka script with no external deps
 - work with world@hey.com feed URLs

And will *not*:

 - guarantee correct parsing of feeds from other services
 - render the posts into anything other than a basic .html page or .edn file.
 - handle automation internally
 - detect changes to the feed; only pull/compare every time the script runs

This project is considered complete when the above requirements are met with clearly working functionality. That is, the invokation of the script, with the proper URL parameter, must successfully download, parse, and save the blog entries to my save directory.
 
** Meta-Problem
I have a problem of not always finishing my work. As a self-taught dev, I often worry that I'm missing big important skills in software development, and one thing I know for sure is that an inability to /finish/ projects is a problem. This project is the first of a series of small yet concrete projects that can be /well-designed/, /well-scoped/, and clearly considered *finished* once the design goal has been met.

In short, this project aims to solve my meta-problem of having a weak ability to design and complete software projects. This design doc is a specific effort on my part to be clear up-front about the project's goals and intent.

** RSS
Here's my RSS link that I'll be using:

[[https://world.hey.com/adam.james/feed.atom]]

I assume that the atom file at that address is automatically updated any time a post is created, and I assume it's just XML with all of the blog's content.

What I'm pretty sure RSS does:

Every time the site updates, the feed.atom file is re-generated with the newest content appended. Then, the RSS reader is a separate app that polls feed.atom URLs, downloads them, and parses/displays the contents according to the app's design.

Using these assumptions, I am making a very simple tool that just pulls the entire feed XML every time, compares it to a cached file, and parses new entries into some structure which can be saved.

** Downloading the Feed XML
To download the feed, I will simply use ~(slurp url)~.

** Parsing
To parse the feed, I am using ~clojure.data.xml~ and some zipper manipulation functions. The feed is parsed into an XML tree. At this point, I can grab a list of nodes that match the /entry/ tag. It is this list of entries over which I map various functions to clean up and ultimately save the entries as files (.html or .edn) in the posts directory.

My format of choice is a .edn file which is just the Clojure map for each entry saved to a file. The map contains the following keys: ~(:email :content :updated :name :title :link :id :post :published)~. Most keys are self-explanatory, but I want to note the ~:post~ and ~:content~ keys, which are a bit ambiguous.

The ~:content~ key is the /unmodified/ XML tree node that comes from the initial parse of the feed. This is left so that any future scripts or rendering functions still have access to the entirety of the unchanged data.

The ~:post~ key contains the /parsed and modified/ *Hiccup* data structure, which follows some specific logic for formatting and improving the html's structure. For example, instead of plain strings and <br> tags, <p> tags are used. This data manipulation is suited to *my* purposes, and leaves a nice, clean, hiccup structure for future rendering scripts. It is exactly this ~:post~ value that gets rendered when exporting the basic .html page. If other users wish to handle the posts differently, they can use the ~:content~ key as previously mentioned.

** Caching
To cache, I save the downloaded feed.xml into the posts directory. Then, whenever the script is run, I slurp both the current feed from the URL and the previous feed from the local file. With each in memory, I parse them into XML trees and get the entry nodes into a set. Removing from the /current/ set all entries from the /previous/ set, I am left with only new posts. If the set is empty, no further action is taken and the script terminates with a message.

** Saving
All saving (of the cache and posts) is handled with ~(spit (str dir file))~. Formats are limited to .html and .edn, and the main reason .html is provided is because I get it 'for free' because I want to have my posts saved in .edn files with a clean Hiccup style structure.

** Using Babashka
I want to use Babashka because I really love Clojure but want a tool that is mentally 'lightweight' and very quick and easy. Babashka /v0.6.0/ has a bunch of built in libraries already and works quickly and reliably. I won't need any dependencies to be downloaded for this script, which keeps its portability high, and makes it straight forward for other people to fork and modify the script for their own purposes, if they desire.

** World@Hey.com Only
I am only guaranteeing that the parsing strategy in this script will work for hey.com feeds, as I really don't want to cover other scenarios. I can't predict what other people might want from other feeds. The strategy in this script is quite simple, so anyone could modify things to fit the feeds they care about anyway. As well, I do also save the un-modified content node, which can be used to construct whatever render someone could want.

Other feeds may actually work fine, but I'm not guaranteeing it. Nor am I going to modify my script to handle them.

* main
** ns
Need xml parsing. Might need to build a zipper to edit nodes.

I'll want to run it as a CLI, and probably want to turn the project into another GRAALVM native image example, so I'll need tools.cli as well.

As part of the design criteria, I want this to work without pulling any new libraries from outside of the babashka tool. This means sticking with clojure.data.xml even though other libraries might be a little more straight forward. I can build a zipper editor easily enough so it's not a problem.

#+begin_src clojure :tangle ./rss-saver.clj
#!/usr/local/bin/bb
(ns rss-saver.main
  (:require [clojure.string :as str]
            [clojure.data.xml :as xml]
            [clojure.java.io :as io]
            [clojure.zip :as zip]
            [clojure.java.shell :as sh :refer [sh]]
            [clojure.tools.cli :as cli]
            [hiccup2.core :refer [html]]))

#+end_src

** zipper tools
#+begin_src clojure :tangle ./rss-saver.clj
;; https://ravi.pckl.me/short/functional-xml-editing-using-zippers-in-clojure/
(defn edit-nodes
  [zipper matcher editor]
  (loop [loc zipper]
    (if (zip/end? loc)
      (zip/root loc)
      (if-let [matcher-result (matcher loc)]
        (let [new-loc (zip/edit loc editor)]
          (if (not (= (zip/node new-loc) (zip/node loc)))
            (recur (zip/next new-loc))
            (recur (zip/next loc))))
        (recur (zip/next loc))))))

(defn remove-nodes
  [zipper matcher]
  (loop [loc zipper]
    (if (zip/end? loc)
      (zip/root loc)
      (if-let [matcher-result (matcher loc)]
        (let [new-loc (zip/remove loc)]
          (recur (zip/next new-loc)))
        (recur (zip/next loc))))))

(defn get-nodes
  [zipper matcher]
  (loop [loc zipper
         acc []]
    (if (zip/end? loc)
      acc
      (if (matcher loc)
        (recur (zip/next loc) (conj acc (zip/node loc)))
        (recur (zip/next loc) acc)))))

(defn match-entry?
  [loc]
  (let [node (zip/node loc)
        {:keys [tag]} node]
    (= tag :entry)))
  
#+end_src

** entry nodes
#+begin_src clojure :tangle ./rss-saver.clj
(defn feed-str->entries
  "Returns a sequence of parsed article entry nodes from an XML feed string."
  [s]
  (-> s
      (xml/parse-str {:namespace-aware false})
      zip/xml-zip
      (get-nodes match-entry?)))

#+end_src

** node-transforms
*** normalize
#+begin_src clojure :tangle ./rss-saver.clj
(defn normalize-entry
  "Normalizes the entry node by flattening content into a map."
  [entry]
  (let [content (filter map? (:content entry))
        f (fn [{:keys [tag content] :as node}]
            (let [val (cond (= tag :link) (get-in node [:attrs :href])
                            :else (first content))]
                {tag val}))
        author-map (->> content
                        (filter #(= (:tag %) :author))
                        first :content
                        (filter map?)
                        (map f)
                        (apply merge))]
   (apply merge (conj
                 (map f (remove #(= (:tag %) :author) content))
                 author-map))))
#+end_src

*** clean-html
#+begin_src clojure :tangle ./rss-saver.clj
(defn match-tag
  [k]
  (fn
    [loc]
    (let [node (zip/node loc)
          {:keys [tag]} node]
      (= tag k))))

(defn wrap-strs-in-p-tags
  [node]
  (let [f (fn [item]
            (if (string? item)
              {:tag :p :attrs {} :content [item]}
              item))
        new-content (->> node
                         :content
                         (map f))]
    (assoc node :content new-content)))

(defn convert-to-p-tag
  [node]
  (assoc node :tag :p))

(defn unwrap-img-from-figure
  [node]
  (let [img-node (-> node
                 zip/xml-zip
                 (get-nodes (match-tag :img))
                 first)
        new-attrs (-> img-node
                      :attrs
                      (dissoc :srcset :decoding :loading))]
    (assoc img-node :attrs new-attrs)))

(defn clean-html
  "Clean up the html string from the feed."
  [s]
  (let [s (-> s
              (str/replace "<br>" "<br></br>")
              (str/replace #"<img[\w\W]+?>" #(str %1 "</img>")))]
    (-> s
        (xml/parse-str {:namespace-aware false})
        zip/xml-zip
        (edit-nodes (match-tag :figure) unwrap-img-from-figure)
        xml/emit-str
        (str/replace #"<\?xml[\w\W]+?>" ""))))

#+end_src

** hiccup
#+begin_src clojure :tangle ./rss-saver.clj
(defmulti node->hiccup
  (fn [node]
    (cond
      (map? node) (:tag node)
      (and (seqable? node) (not (string? node))) :list
      :else :string)))

(defmethod node->hiccup :string
  [node]
  (when-not (= (str/trim node) "") node))

(defn de-dupe
  [list]
  (->> list
       (partition-by identity)
       (map first)))

(defn selective-flatten
  ([l] (selective-flatten [] l))
  ([acc l]
   (if (seq l)
     (let [item (first l)
           xacc (if (or (string? item)
                        (and (vector? item) (keyword? (first item))))
                 (conj acc item)
                 (into [] (concat acc (selective-flatten item))))]
       (recur xacc (rest l)))
     (apply list acc))))

(defmethod node->hiccup :list
  [node]
  (->> node
       (map node->hiccup)
       (remove nil?)
       de-dupe
       selective-flatten))

(defmethod node->hiccup :div [node] (node->hiccup (:content node)))

(defmethod node->hiccup :default
  [{:keys [tag attrs content]}]
  [tag attrs (node->hiccup content)])

(defn inline-elem? [item] (when (#{:em :strong :a} (first item)) true))
(defn inline? [item] (or (string? item) (inline-elem? item)))

(defn group-inline
  [list]
  (let [groups (partition-by inline? list)
        f (fn [l]
            (if (not= (first (first l)) :br)
              (into [:p] l)
              l))]
    (->> groups
         (map f)
         selective-flatten
         (remove #(= :br (first %))))))

(defn html-str->hiccup
  "Parses and converts an html string to markdown."
  [s]
  (-> s
      (xml/parse-str {:namespace-aware false})
      node->hiccup
      group-inline
      de-dupe))

(defn entry->edn
  "Converts a parsed XML entry node into a Hiccup data structure."
  [entry]
  (let [entry (normalize-entry entry)]
    {:id (:id entry)
     :post (assoc entry :post (->> entry :content
                                   clean-html
                                   html-str->hiccup))}))
#+end_src

** basic-html
#+begin_src clojure :tangle ./rss-saver.clj
(defn readable-date
  [s]
  (as-> s s
    (str/split s #"[a-zA-Z]")
    (str/join " " s)))

(defn entry->html
  "Converts a parsed XML entry node into an html document."
  [entry]
  (let [entry (normalize-entry entry)
        info-span (fn [label s]
                    [:span {:style {:display "block"
                                    :margin-bottom "2px"}}
                     [:strong label] s])]
    (assoc entry :post
           (->
            (str
            "<!DOCTYPE html>\n"
            (html
             {:mode :html}
             [:head
              [:meta {:charset "utf-8"}]
              [:title (:title entry)]]
             [:body
              [:div {:class "post-info"}
               (info-span "Author: " (:name entry))
               (info-span "Email: " (:email entry))
               (info-span "Published: " (:published entry))
               (info-span "Updated: " (:updated entry))]
              [:a {:href (:link entry)} [:h1 (:title entry)]]
              (->> entry :content
                   clean-html
                   html-str->hiccup)]))
           (str/replace #"</br>" "")))))
#+end_src

** CLI
#+begin_src clojure :tangle ./rss-saver.clj
(def cli-options
  [["-h" "--help"]
   ["-u" "--url URL" "The URL of the RSS feed you want to save."]
   ["-d" "--dir DIR" "The directory where articles will be saved."
    :default "./posts"]
   ["-f" "--format FORMAT" "The format of saved articles. Either 'html' or 'edn' for a Clojure Map with the post saved as Hiccup style syntax. Defaults to edn if unspecified."
    :default "edn"]
   ["-c" "--clear" "Clear the cached copy of the previous feed."]
   ["-s" "--silent" "Silence the script's output."]])

(defn clear!
  [opts]
  (let [prev-fname (str (:dir opts) "/" "previous-feed.atom")]
    (sh "rm" "-f" prev-fname)))

(defn save!
  [opts]
  (let [save-fn (get {"html" entry->html
                      "edn" entry->edn} (:format opts))
        cur-str (slurp (:url opts))
        prev-fname (str (:dir opts) "/" "previous-feed.atom")
        prev-str (when (.exists (io/file prev-fname))
                   (slurp prev-fname))
        prev (when prev-str (feed-str->entries prev-str))
        cur (feed-str->entries cur-str)
        entries (remove (into #{} prev) cur)]
    (if (> (count entries) 0)
      (do
        (when-not (:silent opts)
          (println "Handling" (count entries) "entries as" (str (:format opts) ".")))
        
        (sh "mkdir" "-p" (:dir opts))
        (doseq [{:keys [id post]} (mapv save-fn entries)]
          (let [fname (str
                       (:dir opts) "/"
                       (second (str/split id #"/")) "."
                       (:format opts))]
            (spit fname post)))
        (spit prev-fname cur-str))

      (when-not (:silent opts)
        (println "No changes found in feed.")))))

(defn -main
  [& args]
  (let [parsed (cli/parse-opts args cli-options)
        opts (:options parsed)]
    (cond
      (:help opts)
      (println "Usage:\n" (:summary parsed))

      (nil? (:url opts))
      (when-not (:silent opts)
        (println "Please specify feed URL."))

      (not (#{"html" "edn"} (:format opts)))
      (when-not (:silent opts)
        (println "Invalid format:" (:format opts)))

      :else
      (do
        (when (:clear opts) (clear! opts))
        (save! opts)))))

(apply -main *command-line-args*)
(shutdown-agents)
#+end_src

* tests
#+begin_src clojure
(def opts {:url "https://world.hey.com/adam.james/feed.atom"
           :dir "posts"
           :format "md"})

(def entries (feed-str->entries (slurp (:url opts))))
#_(entry->markdown (nth entries 6))
#_(save! opts)

#+end_src
